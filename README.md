# ML

## 学习

学习的内容都是前人思想的结晶,在理解的时候,每个人想法不同,会有理解上的偏差,但是总的来说是好的,站在巨人的肩膀上

就好比如果没有前人,就不会有计算机,但是计算机是必然会出现的产物,如果我们这一代才开始研究计算机,那么社会的发展不就滞后了吗?这就是传承的意义所在,而且后人不一定都需要知道计算机的原理,但是照样可以使用计算机,就好比用计算机打游戏,了解原理和使用需要的时间和精力都是不同的,不同的侧重点也就意味着不同的选择

对于图像和语言而言，这里其实最难的是如何定量的去分析他们，如何将其转化为计算可以解决的内容，这个才是比较复杂的内容。这可能就是数学建模的意义吧，如何将实际问题转化为数学问题去解决。

## 流程

1. 读取数据,观察数据
2. 处理数据,处理数据空缺和数值化
3. 分割数据集,训练集/测试集
3. 标准化
4. 选择模型,训练
5. 模型评估
6. 预测

## 距离和相似性度量

### 距离

1. [欧几里得距离](https://zh.wikipedia.org/zh-hans/%E6%AC%A7%E5%87%A0%E9%87%8C%E5%BE%97%E8%B7%9D%E7%A6%BB)
2. [minkowski distance](https://zh.wikipedia.org/wiki/%E6%98%8E%E6%B0%8F%E8%B7%9D%E7%A6%BB)
3. [马氏距离](https://zh.wikipedia.org/wiki/%E9%A9%AC%E5%93%88%E6%8B%89%E8%AF%BA%E6%AF%94%E6%96%AF%E8%B7%9D%E7%A6%BB)
4. [汉明距离](https://zh.wikipedia.org/wiki/%E6%B1%89%E6%98%8E%E8%B7%9D%E7%A6%BB)
5. [余弦相似性](https://zh.wikipedia.org/wiki/%E4%BD%99%E5%BC%A6%E7%9B%B8%E4%BC%BC%E6%80%A7)
6. [编辑距离](https://zh.wikipedia.org/wiki/%E7%B7%A8%E8%BC%AF%E8%B7%9D%E9%9B%A2)
7. [雅卡尔距离](https://zh.wikipedia.org/wiki/%E9%9B%85%E5%8D%A1%E5%B0%94%E6%8C%87%E6%95%B0)

### 相似性

1. [KL散度](https://zh.wikipedia.org/wiki/%E7%9B%B8%E5%AF%B9%E7%86%B5)
2. [信息熵](https://zh.wikipedia.org/wiki/%E7%86%B5_(%E4%BF%A1%E6%81%AF%E8%AE%BA))


## 分类和回归

分类:
给定一组数据,训练模型,最后给定不知分类的数据,希望通过这个模型给出预测的分类

回归
给定一组数据,训练模型,最后给定不知结果的数据,希望通过这个模型可以预测结果

区别:
分类的结果是离散的
回归的结果是连续的

## 数据预处理

### 缺失数据
1. 删除空数据
2. 通过均值补缺

### 类别数据
1. 可以直接转化为数值数据,这类数据可以比较
2. 没有大小之分,可以直接转化为bool类型,
3. 如果有多个类别则直接拆分为多列(one hot)
4. multi-hot 

### 归一化
将特征取值放到`[0,1]`范围内

### 标准化
数据通过处理后,否和标准正太分布,这样可以让模型快速收敛

### 特征选择
序列后向选择(减少特征,计算所有特征组合)


### 特征排序
随机森林(不需要对数据进行标准化和归一化)


## 线性模型

### 线性回归

1. 最小二乘法, 给定数据可以曲线拟合
2. 梯度下降法, 寻找最小值
3. 房价预测, housing数据

### 逻辑回归

1. 极大似然法
2. 花分类, iris数据


### 评估模型

1. MSE均方误差
2. R2 Score


## 决策树

1. 熵, 信息论
2. 树, 训练的过程就是构建树,分类的过程就是搜索


## KNN

1. 度量数据距离
2. 邻居个数k选择
3. 维度增加,过拟合风险增加,可通过降维和特征选择解决过拟合

## SVM

1. 二次规划
2. 核函数

## 神经网络

1. 线性组合
2. 激活函数, 进行非线性变换
3. 损失函数, 目标让损失函数最小, 梯度下降/反向传播

## 深度学习

### 过拟合

1. 正则化
2. dropout

### 卷积神经网络
Convolutional Neural Network (CNN) 卷积神经网络 
图像处理

### 循环神经网络
Recurrent Neural Network (RNN) 循环神经网络 
自然语言处理


### 深度学习框架
TensorFlow

## 贝叶斯分类器

极大似然估计, 统计数理学方案，总体就是一类概率分布，极大似然函数去的偏导确定概率分布中的参数的方法
条件概率
p(A|B) = p(AB)/p(B)
p(B|A) = p(BA)/p(A)
AB = BA
p(AB) = p(BA) = p(A|B)p(B) = p(B|A)p(A)

贝叶斯公式， p(B|A) = p(AB)/p(B) = p(A|B)p(B) / p(B)

其中p(B)可以继续按照全概率公式进行展开


## 工具

### 梯度下降法

#### 问题

如何找到函数的极小值,如果是最小值就更好了

#### 老方法

求导数,导数为0的地方,对应x的值

#### 新方法

梯度就是各个特征偏导数的向量表示, 让特征在他梯度下降的方向上不断的更新,从而让所求的函数达到最小

#### 对比

相同点:
都需要求导

不同点:
老方法: 需要继续解方程
新方法: 不断变化更新x的值,只是带入方程求解


## 参考
1. [sklearn](https://scikit-learn.org/)
2. [pandas](https://pandas.pydata.org/)
3. [numpy](http://www.numpy.org/)
4. [matplotlib](https://matplotlib.org/)
5. [uci](http://archive.ics.uci.edu/ml/index.php)
6. [playground tensorflow](http://playground.tensorflow.org)
7. [神经网络与深度学习](https://nndl.github.io/)







